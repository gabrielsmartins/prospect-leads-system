server:
  port: 8086

spring:
  application:
    name: lead-service
  main:
    allow-bean-definition-overriding: true
  data:
    mongodb:
      uuid-representation: standard
  redis:
    client-name: ${spring.application.name}
    client-type: LETTUCE
    lettuce:
      pool:
        enabled: true
  sleuth:
    enabled: true
    trace-id128: true
    opentracing:
      enabled: true
  kafka:
    admin:
      auto-create: true
    bootstrap-servers: localhost:9092
    properties:
      request.timeout.ms: 20000
      retry.backoff.ms: 500
      value.subject.name.strategy: io.confluent.kafka.serializers.subject.TopicRecordNameStrategy
      schema.registry.url: http://localhost:8081
    listener:
      ack-mode: MANUAL_IMMEDIATE
    consumer:
      group-id: ${spring.application.name}
      auto-offset-reset: earliest
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      schema.registry.url: ${spring.kafka.properties.schema.registry.url}
      auto.register.schemas: true
      properties:
        specific.avro.reader: true
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      schema.registry.url: ${spring.kafka.properties.schema.registry.url}
      acks: all
      auto.register.schemas: true
      properties:
        enable.idempotence: true

redis:
  streams:
    key: event:leads
    group: ${spring.application.name}

topic:
  input:
    notification-emitted: notification-emitted
  output:
    lead-processed: lead-processed

org:
  jobrunr:
    database:
      skip-create: false
      table-prefix: _jobrunr # allows to set a table prefix (e.g. schema  or schema and tableprefix for all tables. e.g. MYSCHEMA._jobrunr)
      database-name: jobrunr # Override the default database name to use (e.g. use main application database)
      datasource:  # allows to specify a DataSource specifically for JobRunr
      type: redis-lettuce  # if you have multiple supported storage providers available in your application (e.g. an SQL DataSource and Elasticsearch), it allows to specify which database to choose. Valid values are 'sql', 'mongodb', 'redis-lettuce', 'redis-jedis' and 'elasticsearch'.
    jobs:
      default-number-of-retries: 3 #the default number of retries for a failing job
      retry-back-off-time-seed: 5 #the default time seed for the exponential back-off policy.
    job-scheduler:
      enabled: true
    background-job-server:
      enabled: true
      worker-count: 1 #this value normally is defined by the amount of CPU's that are available
      poll-interval-in-seconds: 15 #check for new work every 15 seconds
      delete-succeeded-jobs-after: 36 #succeeded jobs will go to the deleted state after 36 hours
      permanently-delete-deleted-jobs-after: 72 #deleted jobs will be deleted permanently after 72 hours
      metrics:
        enabled: true #Micrometer integration - this was true in v5.
    dashboard:
      enabled: true
      port: 9000 #the port on which to start the dashboard
    miscellaneous:
      allow-anonymous-data-usage: false #this sends the amount of succeeded jobs for marketing purposes

springdoc:
  swagger-ui:
    path: /swagger-ui.html
  api-docs:
    path: /api-docs

management:
  endpoint:
    metrics:
      enabled: true
    prometheus:
      enabled: true
  endpoints:
    web:
      exposure:
        include: health, metrics, prometheus

eureka:
  client:
    enabled: true
    register-with-eureka: true